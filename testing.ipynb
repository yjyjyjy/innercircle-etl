{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5ce3b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrape_metadata as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b9e5fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "contract = '0x7fa6b489a0dd62967406c25b478a209f81a707de'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbc6d819",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = sc.get_contract_meta_data_from_opensea_selenium(contract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb246c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'address': '0x7fa6b489a0dd62967406c25b478a209f81a707de',\n",
       " 'name': 'Abandoned Kid Kongz',\n",
       " 'safelist_request_status': None,\n",
       " 'description': 'Formally know as \"Kid Kongz\"\\nStarting off this year, 4000 Kid Kongz were created & minted out within minutes, with a community hyped, excited and ecstatic about the project. We unfortunately were given false hope, ignored and ultimately RUGGED....\\n\\n\\n',\n",
       " 'image_url': 'https://lh3.googleusercontent.com/CgEeCAy-9amtO7JbHNdGjCOcgmStoRlJBmiy7onkxGNaFWTFbQAPrTtAadrS_C6YFA6rTJ2MF09F9SC_ZN2kjzyvDfh5kikTs7uc=s130',\n",
       " 'banner_image_url': 'https://lh3.googleusercontent.com/2qtKb9r2GhUQB4uGugDHXwV8Ytch4-LYs2KNBSx8iTMO4Z37LHlJVZ02tETcWY3ZB9OE-OH4VkPHAzEMn7WmHSO4Iwq-Vocjfj9QpA=h600',\n",
       " 'external_url': 'https://daycarekidz.com/',\n",
       " 'twitter_username': 'KaijuKidz',\n",
       " 'discord_url': 'https://discord.gg/ak643YTjZE',\n",
       " 'telegram_url': None,\n",
       " 'instagram_username': None,\n",
       " 'medium_username': None,\n",
       " 'wiki_url': None,\n",
       " 'payout_address': None,\n",
       " 'slug': 'abandonedkidkongz'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e28d8e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import etl_utls as utl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c05aea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame()\n",
    "row = pd.DataFrame(meta, index=[0])\n",
    "if output.empty:\n",
    "    output = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d196c066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f04f209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒ¿ Load a python df into postgres\n",
      "ðŸŒ¿ Upsert into /Users/junyuyang/code/ddhub/whale-watching/tmp_dataframe_2022-02-11_14_14_57_431774.csv into collection at: 2022-02-11 14:14:57.436204\n",
      "Connecting to the PostgreSQL database...\n",
      "ðŸ“º Got Postgress Connection\n",
      "ðŸŒ¿ðŸŒ¿ executing query on postgres:2022-02-11 14:14:57.835321\n",
      "drop table if exists collection_staging\n",
      "ðŸŒ¿ðŸŒ¿ finished: 2022-02-11 14:14:58.104979\n",
      "Connecting to the PostgreSQL database...\n",
      "ðŸ“º Got Postgress Connection\n",
      "ðŸŒ¿ðŸŒ¿ executing query on postgres:2022-02-11 14:14:58.480783\n",
      "create table collection_staging as select * from collection limit 0\n",
      "ðŸŒ¿ðŸŒ¿ finished: 2022-02-11 14:14:58.694813\n",
      "ðŸŒ¿ Loading /Users/junyuyang/code/ddhub/whale-watching/tmp_dataframe_2022-02-11_14_14_57_431774.csv into collection_staging at: 2022-02-11 14:14:58.695506\n",
      "Connecting to the PostgreSQL database...\n",
      "ðŸ“º Got Postgress Connection\n",
      "ðŸŒ¿ðŸŒ¿ executing query on postgres:2022-02-11 14:14:59.072304\n",
      "\n",
      "    COPY collection_staging\n",
      "    FROM '/Users/junyuyang/code/ddhub/whale-watching/tmp_dataframe_2022-02-11_14_14_57_431774.csv'\n",
      "    DELIMITER ','\n",
      "    CSV HEADER;\n",
      "    \n",
      "ðŸ¤¯ Error querying postgres: \n",
      "could not open file \"/Users/junyuyang/code/ddhub/whale-watching/tmp_dataframe_2022-02-11_14_14_57_431774.csv\" for reading: No such file or directory\n",
      "HINT:  COPY FROM instructs the PostgreSQL server process to read a file. You may want a client-side facility such as psql's \\copy.\n",
      "\n"
     ]
    },
    {
     "ename": "UndefinedFile",
     "evalue": "could not open file \"/Users/junyuyang/code/ddhub/whale-watching/tmp_dataframe_2022-02-11_14_14_57_431774.csv\" for reading: No such file or directory\nHINT:  COPY FROM instructs the PostgreSQL server process to read a file. You may want a client-side facility such as psql's \\copy.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUndefinedFile\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wh/rys7bm612m9bl7l6fypy_r3m0000gn/T/ipykernel_13728/2850061747.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mutl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_from_df_to_postgres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"collection\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_upsert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/ddhub/whale-watching/etl_utls.py\u001b[0m in \u001b[0;36mcopy_from_df_to_postgres\u001b[0;34m(df, table, csv_filename_with_path, use_upsert, key)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ðŸ¤¯ executing upsert without providing key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mupsert_from_file_to_postgres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_filename_with_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcsv_filename_with_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mcopy_from_file_to_postgres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_filename_with_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcsv_filename_with_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/ddhub/whale-watching/etl_utls.py\u001b[0m in \u001b[0;36mupsert_from_file_to_postgres\u001b[0;34m(csv_filename_with_path, table, key)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"ðŸŒ¿ Upsert into {csv_filename_with_path} into {table} at: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mstaging_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_staging_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mcopy_from_file_to_postgres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_filename_with_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstaging_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mupsert_postgres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstaging_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mquery_postgres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"drop table if exists {staging_table}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/ddhub/whale-watching/etl_utls.py\u001b[0m in \u001b[0;36mcopy_from_file_to_postgres\u001b[0;34m(csv_filename_with_path, table)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mCSV\u001b[0m \u001b[0mHEADER\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mquery_postgres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/ddhub/whale-watching/etl_utls.py\u001b[0m in \u001b[0;36mquery_postgres\u001b[0;34m(sql, columns)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ðŸŒ¿ðŸŒ¿ executing query on postgres:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mdata_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUndefinedFile\u001b[0m: could not open file \"/Users/junyuyang/code/ddhub/whale-watching/tmp_dataframe_2022-02-11_14_14_57_431774.csv\" for reading: No such file or directory\nHINT:  COPY FROM instructs the PostgreSQL server process to read a file. You may want a client-side facility such as psql's \\copy.\n"
     ]
    }
   ],
   "source": [
    "utl.copy_from_df_to_postgres(df=output, table=\"collection\", use_upsert=True, key=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbb79c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import etl_utls as utl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d66be58f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (3130161944.py, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/wh/rys7bm612m9bl7l6fypy_r3m0000gn/T/ipykernel_13398/3130161944.py\"\u001b[0;36m, line \u001b[0;32m42\u001b[0m\n\u001b[0;31m    return meta\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "collection_keys = [\n",
    "    \"name\",\n",
    "    \"safelist_request_status\",\n",
    "    \"description\",\n",
    "    \"image_url\",\n",
    "    \"banner_image_url\",\n",
    "    \"external_url\",\n",
    "    \"twitter_username\",\n",
    "    \"discord_url\",\n",
    "    \"telegram_url\",\n",
    "    \"instagram_username\",\n",
    "    \"medium_username\",\n",
    "    \"wiki_url\",\n",
    "    \"payout_address\",\n",
    "    \"slug\",\n",
    "]\n",
    "meta = {\"address\": contract}\n",
    "for key in collection_keys:\n",
    "    meta[key] = None\n",
    "\n",
    "# starting a headless browser\n",
    "browser = webdriver.Chrome()\n",
    "\n",
    "# navigate browser to find the collection\n",
    "browser.get(\"https://opensea.io\")\n",
    "time.sleep(2)\n",
    "input_box = browser.find_element_by_xpath('//input[@type=\"text\"]')\n",
    "input_box.send_keys(contract)\n",
    "input_box.send_keys(Keys.RETURN)\n",
    "wait_upto = 10\n",
    "\n",
    "timer = 0\n",
    "while timer <= wait_upto:\n",
    "    cards = browser.find_elements_by_xpath(\"//div[contains(@class, 'CollectionSearchCarousel--one-card')]\")\n",
    "    if len(cards) > 0:\n",
    "        break\n",
    "    timer += 1\n",
    "\n",
    "if len(cards) == 0:\n",
    "    print(f\"ðŸŒŠðŸŒŠ failed to find collection on OpenSea via selenium: {contract}. Saving Unnamed\")\n",
    "    meta[\"name\"] = \"Unnamed\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "450bcaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "257ce60a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'server' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wh/rys7bm612m9bl7l6fypy_r3m0000gn/T/ipykernel_13728/2554035045.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mssh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateSSHClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mscp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSCPClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mssh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'server' is not defined"
     ]
    }
   ],
   "source": [
    "import paramiko\n",
    "from scp import SCPClient\n",
    "\n",
    "def createSSHClient(server, port, user, password):\n",
    "    client = paramiko.SSHClient()\n",
    "    client.load_system_host_keys()\n",
    "    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "    client.connect(server, port, user, password)\n",
    "    return client\n",
    "\n",
    "server = \n",
    "ssh = createSSHClient(server='34.134.16.86', port, user, password)\n",
    "scp = SCPClient(ssh.get_transport())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8a26b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('scp tmp_dataframe_2022-02-11_14_14_57_431774.csv junyuyang@34.134.16.86:/home/junyuyang/csv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b35be12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
